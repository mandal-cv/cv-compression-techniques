{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a156529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from distiller import Distiller\n",
    "#import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee08077",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d0270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 44s 26ms/step - loss: 0.1962 - accuracy: 0.9416 - val_loss: 0.0702 - val_accuracy: 0.9793\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 41s 24ms/step - loss: 0.1204 - accuracy: 0.9639 - val_loss: 0.0730 - val_accuracy: 0.9785\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 41s 25ms/step - loss: 0.1055 - accuracy: 0.9695 - val_loss: 0.0625 - val_accuracy: 0.9822\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 40s 24ms/step - loss: 0.0947 - accuracy: 0.9721 - val_loss: 0.0637 - val_accuracy: 0.9812\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 39s 23ms/step - loss: 0.0876 - accuracy: 0.9744 - val_loss: 0.0774 - val_accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x260f2742580>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(100),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10),\n",
    "    ],)\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "q_aware_model = quantize_model(keras.models.clone_model(model))\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_split=0.1,\n",
    ")\n",
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f125ffc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 62s 36ms/step - loss: 0.2022 - accuracy: 0.9382 - val_loss: 0.0711 - val_accuracy: 0.9798\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 61s 36ms/step - loss: 0.1198 - accuracy: 0.9648 - val_loss: 0.0637 - val_accuracy: 0.9815\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 61s 36ms/step - loss: 0.1076 - accuracy: 0.9683 - val_loss: 0.0702 - val_accuracy: 0.9808\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 60s 36ms/step - loss: 0.0975 - accuracy: 0.9714 - val_loss: 0.0619 - val_accuracy: 0.9825\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 61s 36ms/step - loss: 0.0902 - accuracy: 0.9743 - val_loss: 0.0620 - val_accuracy: 0.9827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x260f09818e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46090bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 77s 45ms/step - loss: 0.1968 - accuracy: 0.9401 - val_loss: 0.0615 - val_accuracy: 0.9828\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 77s 46ms/step - loss: 0.1179 - accuracy: 0.9646 - val_loss: 0.0597 - val_accuracy: 0.9822\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 76s 45ms/step - loss: 0.1066 - accuracy: 0.9689 - val_loss: 0.0686 - val_accuracy: 0.9820\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 75s 44ms/step - loss: 0.0959 - accuracy: 0.9713 - val_loss: 0.0586 - val_accuracy: 0.9818\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 76s 45ms/step - loss: 0.0874 - accuracy: 0.9739 - val_loss: 0.0790 - val_accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2002e912520>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_16_model = quantize_model(# Define the model architecture.\n",
    "        keras.Sequential([\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(100),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10),\n",
    "    ],))\n",
    "\n",
    "q_aware_16_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_16_model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4026f5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2333 - sparse_categorical_accuracy: 0.9293\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9732\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9774A: 1s - loss: 0.0750 - sparse_\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0811 - sparse_categorical_accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0810793787240982, 0.9751999974250793]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the student\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "\n",
    "# Clone student for later comparison\n",
    "student_scratch = keras.models.clone_model(student)\n",
    "q_aware_student = quantize_model(keras.models.clone_model(student))\n",
    "q_aware_16_student = quantize_model(keras.models.clone_model(student))\n",
    "\n",
    "# Train student\n",
    "student_scratch.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train and evaluate student trained from scratch.\n",
    "student_scratch.fit(train_images, train_labels, epochs=3)\n",
    "student_scratch.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821bee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 19s 10ms/step - sparse_categorical_accuracy: 0.9243 - student_loss: 0.2518 - distillation_loss: 0.0086 0s - sparse_categorical_accuracy: 0.9235 - student_loss: 0.2546 - distillation_loss:\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 18s 10ms/step - sparse_categorical_accuracy: 0.9718 - student_loss: 0.0952 - distillation_loss: 0.0036\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 18s 10ms/step - sparse_categorical_accuracy: 0.9759 - student_loss: 0.0806 - distillation_loss: 0.0028\n",
      "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.9730 - student_loss: 0.0861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9729999899864197, 0.012272889725863934]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=model)\n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=40,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "distiller.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df43bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 29s 15ms/step - sparse_categorical_accuracy: 0.9787 - student_loss: 0.0695 - distillation_loss: 0.0023\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 28s 15ms/step - sparse_categorical_accuracy: 0.9810 - student_loss: 0.0625 - distillation_loss: 0.0021\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 28s 15ms/step - sparse_categorical_accuracy: 0.9826 - student_loss: 0.0566 - distillation_loss: 0.0020 5\n",
      "313/313 [==============================] - 1s 4ms/step - sparse_categorical_accuracy: 0.9761 - student_loss: 0.0759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9761000275611877, 0.004243148490786552]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quantize -> distill\n",
    "# Initialize and compile distiller\n",
    "qd = Distiller(student=student, teacher=q_aware_model)\n",
    "qd.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=40,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "qd.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "qd.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10142dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 21s 11ms/step - sparse_categorical_accuracy: 0.9316 - student_loss: 0.2254 - distillation_loss: 0.0082\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 21s 11ms/step - sparse_categorical_accuracy: 0.9705 - student_loss: 0.0983 - distillation_loss: 0.0036\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 21s 11ms/step - sparse_categorical_accuracy: 0.9763 - student_loss: 0.0804 - distillation_loss: 0.0028\n",
      "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.9755 - student_loss: 0.0825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9754999876022339, 0.013444222509860992]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "dq = Distiller(student=q_aware_student, teacher=model)\n",
    "dq.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=40,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "dq.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "dq.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386dbfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 23s 12ms/step - sparse_categorical_accuracy: 0.9212 - student_loss: 0.2618 - distillation_loss: 0.0093\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 22s 12ms/step - sparse_categorical_accuracy: 0.9690 - student_loss: 0.1051 - distillation_loss: 0.0040 1s - sparse_categorical_accuracy: 0.9689 - student_loss: 0.\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 22s 12ms/step - sparse_categorical_accuracy: 0.9748 - student_loss: 0.0846 - distillation_loss: 0.0030\n",
      "313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.9775 - student_loss: 0.0771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9775000214576721, 0.002722498495131731]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "dq_16 = Distiller(student=q_aware_16_student, teacher=model)\n",
    "dq_16.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=40,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "dq_16.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "dq_16.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7033e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.977400004863739\n",
      "Saved baseline model to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp05qxa71e.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e44f4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Aware test accuracy: 0.9811000227928162\n",
      "Saved Q Aware model to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpl61yrowz.h5\n"
     ]
    }
   ],
   "source": [
    "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Q Aware test accuracy:', q_aware_model_accuracy)\n",
    "\n",
    "_, q_aware_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(q_aware_model, q_aware_keras_file, include_optimizer=False)\n",
    "print('Saved Q Aware model to:', q_aware_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "953ca55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distiller test accuracy: 0.9761000275611877\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved Distiller model to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpvywapgq3.h5\n"
     ]
    }
   ],
   "source": [
    "distiller_accuracy, _ = distiller.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Distiller test accuracy:', distiller_accuracy)\n",
    "\n",
    "_, distiller_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(distiller.student, distiller_keras_file, include_optimizer=False)\n",
    "print('Saved Distiller model to:', distiller_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3567dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant -> Distill test accuracy: 0.9761000275611877\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved Quant -> Distill model to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpcqs_9yps.h5\n"
     ]
    }
   ],
   "source": [
    "qd_accuracy, _ = qd.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Quant -> Distill test accuracy:', qd_accuracy)\n",
    "\n",
    "_, qd_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(qd.student, qd_keras_file, include_optimizer=False)\n",
    "print('Saved Quant -> Distill model to:', qd_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dddd7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distill -> Quant test accuracy: 0.9754999876022339\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved Distill -> Quant model to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpghqnzaf7.h5\n"
     ]
    }
   ],
   "source": [
    "dq_accuracy, _ = dq.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Distill -> Quant test accuracy:', dq_accuracy)\n",
    "\n",
    "_, dq_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(dq.student, dq_keras_file, include_optimizer=False)\n",
    "print('Saved Distill -> Quant model to:', dq_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b651e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0434c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 5758115.00 bytes\n",
      "Size of gzipped Q Aware Keras model: 5762168.00 bytes\n",
      "Size of gzipped Distiller Keras model: 78789.00 bytes\n",
      "Size of gzipped Quant -> Distill Keras model: 78789.00 bytes\n",
      "Size of gzipped Distill -> Quant Keras model: 80747.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped Q Aware Keras model: %.2f bytes\" % (get_gzipped_model_size(q_aware_keras_file)))\n",
    "print(\"Size of gzipped Distiller Keras model: %.2f bytes\" % (get_gzipped_model_size(distiller_keras_file)))\n",
    "print(\"Size of gzipped Quant -> Distill Keras model: %.2f bytes\" % (get_gzipped_model_size(qd_keras_file)))\n",
    "print(\"Size of gzipped Distill -> Quant Keras model: %.2f bytes\" % (get_gzipped_model_size(dq_keras_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e9b352f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpmysu49u0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpmysu49u0\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, leaky_re_lu_layer_call_fn, leaky_re_lu_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 35). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp1xdn7gus\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp1xdn7gus\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmps_170lid\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmps_170lid\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp3dw9xsjv\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp3dw9xsjv\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpsz5fuf75\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpsz5fuf75\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp2jeq7xys\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp2jeq7xys\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Found untraced functions such as conv2d_2_layer_call_fn, conv2d_2_layer_call_and_return_conditional_losses, leaky_re_lu_1_layer_call_fn, leaky_re_lu_1_layer_call_and_return_conditional_losses, conv2d_3_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpc9t7nw3j\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpc9t7nw3j\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpw_332k7k\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpw_332k7k\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp1ndw_ote\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp1ndw_ote\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "model_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "model_tflite_model = model_converter.convert()\n",
    "\n",
    "q_aware_converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "q_aware_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "q_aware_tflite_model = q_aware_converter.convert()\n",
    "\n",
    "q8_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "q8_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "q8_tflite_model = q8_converter.convert()\n",
    "\n",
    "q16_converter = tf.lite.TFLiteConverter.from_keras_model(model)#q_aware_16_model)\n",
    "q16_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "q16_converter.target_spec.supported_types = [tf.float16]\n",
    "q16_tflite_model = q16_converter.convert()\n",
    "\n",
    "distiller_converter = tf.lite.TFLiteConverter.from_keras_model(distiller.student)\n",
    "#distiller_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "distiller_tflite_model = distiller_converter.convert()\n",
    "\n",
    "qd_converter = tf.lite.TFLiteConverter.from_keras_model(qd.student)\n",
    "#qd_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "qd_tflite_model = qd_converter.convert()\n",
    "\n",
    "dq_converter = tf.lite.TFLiteConverter.from_keras_model(dq.student)\n",
    "dq_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "dq_tflite_model = dq_converter.convert()\n",
    "\n",
    "dq_8_converter = tf.lite.TFLiteConverter.from_keras_model(distiller.student)#dq_16.student)\n",
    "dq_8_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "dq_8_tflite_model = dq_8_converter.convert()\n",
    "\n",
    "dq_16_converter = tf.lite.TFLiteConverter.from_keras_model(distiller.student)#dq_16.student)\n",
    "dq_16_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "dq_16_converter.target_spec.supported_types = [tf.float16]\n",
    "dq_16_tflite_model = dq_16_converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82dee41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure sizes of models.\n",
    "_, model_file = tempfile.mkstemp('.tflite')\n",
    "_, quant_file = tempfile.mkstemp('.tflite')\n",
    "_, q16_file = tempfile.mkstemp('.tflite')\n",
    "_, q8_file = tempfile.mkstemp('.tflite')\n",
    "_, distiller_file = tempfile.mkstemp('.tflite')\n",
    "_, qd_file = tempfile.mkstemp('.tflite')\n",
    "_, dq_file = tempfile.mkstemp('.tflite')\n",
    "_, dq_8_file = tempfile.mkstemp('.tflite')\n",
    "_, dq_16_file = tempfile.mkstemp('.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ad63905",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(quant_file, 'wb') as f:\n",
    "  f.write(q_aware_tflite_model)\n",
    "\n",
    "with open(q8_file, 'wb') as f:\n",
    "  f.write(q8_tflite_model)\n",
    "\n",
    "with open(q16_file, 'wb') as f:\n",
    "  f.write(q16_tflite_model)\n",
    "\n",
    "with open(model_file, 'wb') as f:\n",
    "  f.write(model_tflite_model)\n",
    "\n",
    "with open(distiller_file, 'wb') as f:\n",
    "  f.write(distiller_tflite_model)\n",
    "\n",
    "with open(qd_file, 'wb') as f:\n",
    "  f.write(qd_tflite_model)\n",
    "\n",
    "with open(dq_file, 'wb') as f:\n",
    "  f.write(dq_tflite_model)\n",
    "\n",
    "with open(dq_8_file, 'wb') as f:\n",
    "  f.write(dq_8_tflite_model)\n",
    "\n",
    "with open(dq_16_file, 'wb') as f:\n",
    "  f.write(dq_16_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80a1b4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model in Mb: 5.9225311279296875\n",
      "Q Aware model in Mb: 1.4943008422851562\n",
      "Quantized 8 model in Mb: 1.494232177734375\n",
      "Quantized 16 model in Mb: 2.9636688232421875\n",
      "Distiller model in Mb: 0.08052825927734375\n",
      "Quant -> Distill model in Mb: 0.08052825927734375\n",
      "Distill -> Quant model in Mb: 0.024322509765625\n",
      "Distill -> Quant 8 model in Mb: 0.0233306884765625\n",
      "Distill -> Quant 16 model in Mb: 0.0423583984375\n"
     ]
    }
   ],
   "source": [
    "print(\"Original model in Mb:\", os.path.getsize(model_file) / float(2**20))\n",
    "print(\"Q Aware model in Mb:\", os.path.getsize(quant_file) / float(2**20))\n",
    "print(\"Quantized 8 model in Mb:\", os.path.getsize(q8_file) / float(2**20))\n",
    "print(\"Quantized 16 model in Mb:\", os.path.getsize(q16_file) / float(2**20))\n",
    "print(\"Distiller model in Mb:\", os.path.getsize(distiller_file) / float(2**20))\n",
    "print(\"Quant -> Distill model in Mb:\", os.path.getsize(qd_file) / float(2**20))\n",
    "print(\"Distill -> Quant model in Mb:\", os.path.getsize(dq_file) / float(2**20))\n",
    "print(\"Distill -> Quant 8 model in Mb:\", os.path.getsize(dq_8_file) / float(2**20))\n",
    "print(\"Distill -> Quant 16 model in Mb:\", os.path.getsize(dq_16_file) / float(2**20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8d1320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original accuracy: 0.977400004863739\n",
      "q aware accuracy: 0.9811000227928162\n",
      "distiller accuracy: 0.9761\n",
      "qd accuracy: 0.9761\n",
      "dq accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "print('original accuracy: ' + str(baseline_model_accuracy))\n",
    "print('q aware accuracy: ' + str(q_aware_model_accuracy))\n",
    "print('distiller accuracy: ' + str(distiller_accuracy))\n",
    "print('qd accuracy: ' + str(qd_accuracy))\n",
    "print('dq accuracy: ' + str(dq_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98e6b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        if i%100 == 0:\n",
    "            print('got to ' + str(i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image.reshape(1, 28, 28, 1))\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "        \n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_digits)):\n",
    "        if prediction_digits[index] == test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c350b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_interpreter = tf.lite.Interpreter(model_content=model_tflite_model)\n",
    "original_interpreter.allocate_tensors()\n",
    "\n",
    "q_aware_interpreter = tf.lite.Interpreter(model_content=q_aware_tflite_model)\n",
    "q_aware_interpreter.allocate_tensors()\n",
    "\n",
    "q8_interpreter = tf.lite.Interpreter(model_content=q8_tflite_model)\n",
    "q8_interpreter.allocate_tensors()\n",
    "\n",
    "q16_interpreter = tf.lite.Interpreter(model_content=q16_tflite_model)\n",
    "q16_interpreter.allocate_tensors()\n",
    "\n",
    "distiller_interpreter = tf.lite.Interpreter(model_content=distiller_tflite_model)\n",
    "distiller_interpreter.allocate_tensors()\n",
    "\n",
    "qd_interpreter = tf.lite.Interpreter(model_content=qd_tflite_model)\n",
    "qd_interpreter.allocate_tensors()\n",
    "\n",
    "dq_interpreter = tf.lite.Interpreter(model_content=dq_tflite_model)\n",
    "dq_interpreter.allocate_tensors()\n",
    "\n",
    "dq_8_interpreter = tf.lite.Interpreter(model_content=dq_8_tflite_model)\n",
    "dq_8_interpreter.allocate_tensors()\n",
    "\n",
    "dq_16_interpreter = tf.lite.Interpreter(model_content=dq_16_tflite_model)\n",
    "dq_16_interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd3de71b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got to 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-e79aedfb82cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mq_aware_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_aware_interpreter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-63-2b54343700f7>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(interpreter)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Run inference.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# Post-processing: remove batch dimension and find the digit with highest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36minvoke\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    921\u001b[0m     \"\"\"\n\u001b[0;32m    922\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_all_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "q_aware_accuracy = evaluate_model(q_aware_interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3197ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating q8...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n"
     ]
    }
   ],
   "source": [
    "print('evaluating q8...')\n",
    "q8_accuracy = evaluate_model(q8_interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f1d6a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating original...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating q16...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating distilled...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating qd...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating dq...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating dq 8...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating dq 16...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n"
     ]
    }
   ],
   "source": [
    "print('evaluating original...')\n",
    "original_accuracy = evaluate_model(original_interpreter)\n",
    "#print('evaluating q aware...')\n",
    "#q_aware_accuracy = evaluate_model(q_aware_interpreter)\n",
    "#print('evaluating q8...')\n",
    "#q8_accuracy = evaluate_model(q8_interpreter)\n",
    "print('evaluating q16...')\n",
    "q16_accuracy = evaluate_model(q16_interpreter)\n",
    "print('evaluating distilled...')\n",
    "distiller_accuracy = evaluate_model(distiller_interpreter)\n",
    "print('evaluating qd...')\n",
    "qd_accuracy = evaluate_model(qd_interpreter)\n",
    "print('evaluating dq...')\n",
    "dq_accuracy = evaluate_model(dq_interpreter)\n",
    "print('evaluating dq 8...')\n",
    "dq_8_accuracy = evaluate_model(dq_8_interpreter)\n",
    "print('evaluating dq 16...')\n",
    "dq_16_accuracy = evaluate_model(dq_16_interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "723b8530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original accuracy  0.9774\n",
      "q aware accuracy  0.9812\n",
      "q8 accuracy  0.9775\n",
      "q16 accuracy  0.9774\n",
      "distiller accuracy  0.9761\n",
      "qd accuracy  0.9761\n",
      "dq accuracy  0.9755\n",
      "dq 8 accuracy  0.9762\n",
      "dq 16 accuracy  0.9761\n"
     ]
    }
   ],
   "source": [
    "print('original accuracy ', original_accuracy)\n",
    "print('q aware accuracy ', q_aware_accuracy)\n",
    "print('q8 accuracy ', q8_accuracy)\n",
    "print('q16 accuracy ', q16_accuracy)\n",
    "print('distiller accuracy ', distiller_accuracy)\n",
    "print('qd accuracy ', qd_accuracy)\n",
    "print('dq accuracy ', dq_accuracy)\n",
    "print('dq 8 accuracy ', dq_8_accuracy)\n",
    "print('dq 16 accuracy ', dq_16_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ca1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
