{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211c89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from distiller import Distiller\n",
    "#import datetime\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9477ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f3d1c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 52s 36ms/step - loss: 1.4882 - accuracy: 0.4616 - val_loss: 1.1876 - val_accuracy: 0.5832\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 54s 38ms/step - loss: 1.1020 - accuracy: 0.6167 - val_loss: 0.9802 - val_accuracy: 0.6550\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 51s 36ms/step - loss: 0.9324 - accuracy: 0.6802 - val_loss: 0.9120 - val_accuracy: 0.6868\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 45s 32ms/step - loss: 0.8112 - accuracy: 0.7191 - val_loss: 0.9338 - val_accuracy: 0.6882\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 43s 30ms/step - loss: 0.7122 - accuracy: 0.7552 - val_loss: 0.8434 - val_accuracy: 0.7230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e0087b3eb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CIFAR10 dataset\n",
    "cifar10 = keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "        keras.Input(shape=(32, 32, 3)),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256),\n",
    "        layers.Dense(10),\n",
    "    ],)\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "q_aware_model = quantize_model(keras.models.clone_model(model))\n",
    "q_aware_16_model = quantize_model(keras.models.clone_model(model))\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_split=0.1,\n",
    ")\n",
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cea694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b58efbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 69s 48ms/step - loss: 1.5950 - accuracy: 0.4151 - val_loss: 1.2766 - val_accuracy: 0.5344\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 70s 50ms/step - loss: 1.1955 - accuracy: 0.5808 - val_loss: 1.0152 - val_accuracy: 0.6414\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 70s 50ms/step - loss: 1.0034 - accuracy: 0.6532 - val_loss: 0.9542 - val_accuracy: 0.6740\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 67s 47ms/step - loss: 0.8779 - accuracy: 0.6958 - val_loss: 0.9116 - val_accuracy: 0.6876\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 69s 49ms/step - loss: 0.7724 - accuracy: 0.7348 - val_loss: 0.8553 - val_accuracy: 0.7098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e0004085b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f13500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 69s 49ms/step - loss: 1.6010 - accuracy: 0.4177 - val_loss: 1.3739 - val_accuracy: 0.5240\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 68s 49ms/step - loss: 1.1834 - accuracy: 0.5833 - val_loss: 1.0387 - val_accuracy: 0.6366\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 68s 49ms/step - loss: 0.9920 - accuracy: 0.6552 - val_loss: 0.9369 - val_accuracy: 0.6812\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 71s 51ms/step - loss: 0.8603 - accuracy: 0.7015 - val_loss: 0.9020 - val_accuracy: 0.6964\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 67s 48ms/step - loss: 0.7552 - accuracy: 0.7366 - val_loss: 0.9838 - val_accuracy: 0.6758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e007d74460>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_16_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_16_model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e32ce7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.4744 - sparse_categorical_accuracy: 0.4623\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0863 - sparse_categorical_accuracy: 0.6217\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.9179 - sparse_categorical_accuracy: 0.6817\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8975 - sparse_categorical_accuracy: 0.6912A: 1s - loss: 0.9035 - sparse_categorica\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8975274562835693, 0.6912000179290771]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the student\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(32, 32, 3)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128),\n",
    "        layers.Dense(10),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "# Clone student for later comparison\n",
    "student_scratch = keras.models.clone_model(student)\n",
    "q_aware_student = quantize_model(keras.models.clone_model(student))\n",
    "q_aware_16_student = quantize_model(keras.models.clone_model(student))\n",
    "\n",
    "# Train student\n",
    "student_scratch.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train and evaluate student trained from scratch.\n",
    "student_scratch.fit(train_images, train_labels, epochs=3)\n",
    "student_scratch.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91df179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 29s 18ms/step - sparse_categorical_accuracy: 0.4758 - student_loss: 1.4452 - distillation_loss: 0.0020 0s - sparse_categorical_accuracy: 0.4724 - student_loss: 1.4540 - distillatio\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 29s 19ms/step - sparse_categorical_accuracy: 0.6268 - student_loss: 1.0648 - distillation_loss: 0.0014\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 33s 21ms/step - sparse_categorical_accuracy: 0.6851 - student_loss: 0.9053 - distillation_loss: 0.0012\n",
      "313/313 [==============================] - 2s 5ms/step - sparse_categorical_accuracy: 0.6801 - student_loss: 0.9385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6801000237464905, 1.1796770095825195]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=model)\n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=40,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "distiller.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "distiller.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c565de18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 45s 28ms/step - sparse_categorical_accuracy: 0.7292 - student_loss: 0.7833 - distillation_loss: 0.0011\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 39s 25ms/step - sparse_categorical_accuracy: 0.7603 - student_loss: 0.6891 - distillation_loss: 0.0013\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 39s 25ms/step - sparse_categorical_accuracy: 0.7863 - student_loss: 0.6123 - distillation_loss: 0.0015\n",
      "313/313 [==============================] - 1s 5ms/step - sparse_categorical_accuracy: 0.7062 - student_loss: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7062000036239624, 0.7706981301307678]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quantize -> distill\n",
    "# Initialize and compile distiller\n",
    "qd = Distiller(student=student, teacher=q_aware_model)\n",
    "qd.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=40,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "qd.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "qd.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c80896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 38s 24ms/step - sparse_categorical_accuracy: 0.4443 - student_loss: 1.5273 - distillation_loss: 0.0022\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 37s 24ms/step - sparse_categorical_accuracy: 0.6036 - student_loss: 1.1250 - distillation_loss: 0.0015 30s - spar - ETA: 25s - sparse_c - ETA: 22s - sparse_categorical_accuracy: 0.5832 - student_loss: 1.1799 - distillation_ - ETA: 22 - ETA: 9s - sparse_categorical_accuracy: 0.5938 - student_loss:  - ETA: 7s - sparse_categorical_accuracy: 0.5966 - student_loss: 1.1415 - dist\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 36s 23ms/step - sparse_categorical_accuracy: 0.6706 - student_loss: 0.9424 - distillation_loss: 0.0012 2s - sparse_categorical_accuracy: 0.6696 \n",
      "313/313 [==============================] - 2s 6ms/step - sparse_categorical_accuracy: 0.6781 - student_loss: 0.9330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6780999898910522, 1.13441801071167]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "dq = Distiller(student=q_aware_student, teacher=model)\n",
    "dq.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=40,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "dq.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "dq.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b4f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 38s 23ms/step - sparse_categorical_accuracy: 0.4470 - student_loss: 1.5181 - distillation_loss: 0.0022 5s - sparse_categorical_accuracy: 0.4276 - student_loss: 1.5644 - dist - ETA: 4s - sparse_categorical_accuracy: 0.4315 - st - ETA: 1s - sparse_categorical_accuracy: 0.4416 - student_loss: 1.5305\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 38s 24ms/step - sparse_categorical_accuracy: 0.6049 - student_loss: 1.1249 - distillation_loss: 0.0015 5s - sparse_categorical_accuracy: 0.5994 - student_loss: 1.1391 - distillation_loss: 0.00 - ETA: 5s - s\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 37s 24ms/step - sparse_categorical_accuracy: 0.6693 - student_loss: 0.9500 - distillation_loss: 0.0012 6\n",
      "313/313 [==============================] - 2s 6ms/step - sparse_categorical_accuracy: 0.6678 - student_loss: 0.9671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6678000092506409, 1.07920241355896]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "dq_16 = Distiller(student=q_aware_16_student, teacher=model)\n",
    "dq_16.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=40,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "dq_16.fit(train_images, train_labels, epochs=3)\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "dq_16.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0655086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.704200029373169\n",
      "Saved baseline model to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpn17kjfgd.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "642e950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Aware test accuracy: 0.6945000290870667\n",
      "Saved Q Aware model to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp6af231q7.h5\n"
     ]
    }
   ],
   "source": [
    "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Q Aware test accuracy:', q_aware_model_accuracy)\n",
    "\n",
    "_, q_aware_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(q_aware_model, q_aware_keras_file, include_optimizer=False)\n",
    "print('Saved Q Aware model to:', q_aware_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14a9e489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distiller test accuracy: 0.7062000036239624\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved Distiller model to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpxjw3_vhe.h5\n"
     ]
    }
   ],
   "source": [
    "distiller_accuracy, _ = distiller.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Distiller test accuracy:', distiller_accuracy)\n",
    "\n",
    "_, distiller_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(distiller.student, distiller_keras_file, include_optimizer=False)\n",
    "print('Saved Distiller model to:', distiller_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e71e58aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant -> Distill test accuracy: 0.7062000036239624\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved Quant -> Distill model to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpfrzv327s.h5\n"
     ]
    }
   ],
   "source": [
    "qd_accuracy, _ = qd.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Quant -> Distill test accuracy:', qd_accuracy)\n",
    "\n",
    "_, qd_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(qd.student, qd_keras_file, include_optimizer=False)\n",
    "print('Saved Quant -> Distill model to:', qd_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ed1a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distill -> Quant test accuracy: 0.6780999898910522\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved Distill -> Quant model to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpu_xd6kz4.h5\n"
     ]
    }
   ],
   "source": [
    "dq_accuracy, _ = dq.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Distill -> Quant test accuracy:', dq_accuracy)\n",
    "\n",
    "_, dq_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(dq.student, dq_keras_file, include_optimizer=False)\n",
    "print('Saved Distill -> Quant model to:', dq_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cf0baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "    # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "724197e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 5074958.00 bytes\n",
      "Size of gzipped Q Aware Keras model: 5083737.00 bytes\n",
      "Size of gzipped Distiller Keras model: 1280610.00 bytes\n",
      "Size of gzipped Quant -> Distill Keras model: 1280608.00 bytes\n",
      "Size of gzipped Distill -> Quant Keras model: 1284811.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped Q Aware Keras model: %.2f bytes\" % (get_gzipped_model_size(q_aware_keras_file)))\n",
    "print(\"Size of gzipped Distiller Keras model: %.2f bytes\" % (get_gzipped_model_size(distiller_keras_file)))\n",
    "print(\"Size of gzipped Quant -> Distill Keras model: %.2f bytes\" % (get_gzipped_model_size(qd_keras_file)))\n",
    "print(\"Size of gzipped Distill -> Quant Keras model: %.2f bytes\" % (get_gzipped_model_size(dq_keras_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63e61ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b9299f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp53g6c6kd\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp53g6c6kd\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, leaky_re_lu_layer_call_fn, leaky_re_lu_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp11qc70ws\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp11qc70ws\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpk5nb61i9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpk5nb61i9\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpjyz1goze\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpjyz1goze\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpdxacv2y_\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpdxacv2y_\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpmk5kdqc7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpmk5kdqc7\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "WARNING:absl:Found untraced functions such as conv2d_4_layer_call_fn, conv2d_4_layer_call_and_return_conditional_losses, leaky_re_lu_4_layer_call_fn, leaky_re_lu_4_layer_call_and_return_conditional_losses, conv2d_5_layer_call_fn while saving (showing 5 of 65). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp5tpd4aw9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp5tpd4aw9\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp0qd3_beq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmp0qd3_beq\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpnhvzff_t\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yeswe\\AppData\\Local\\Temp\\tmpnhvzff_t\\assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "model_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "model_tflite_model = model_converter.convert()\n",
    "\n",
    "q_aware_converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "q_aware_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "q_aware_tflite_model = q_aware_converter.convert()\n",
    "\n",
    "q8_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "q8_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "q8_tflite_model = q8_converter.convert()\n",
    "\n",
    "q16_converter = tf.lite.TFLiteConverter.from_keras_model(model)#q_aware_16_model)\n",
    "q16_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "q16_converter.target_spec.supported_types = [tf.float16]\n",
    "q16_tflite_model = q16_converter.convert()\n",
    "\n",
    "distiller_converter = tf.lite.TFLiteConverter.from_keras_model(distiller.student)\n",
    "#distiller_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "distiller_tflite_model = distiller_converter.convert()\n",
    "\n",
    "qd_converter = tf.lite.TFLiteConverter.from_keras_model(qd.student)\n",
    "#qd_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "qd_tflite_model = qd_converter.convert()\n",
    "\n",
    "dq_converter = tf.lite.TFLiteConverter.from_keras_model(dq.student)\n",
    "dq_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "dq_tflite_model = dq_converter.convert()\n",
    "\n",
    "dq_8_converter = tf.lite.TFLiteConverter.from_keras_model(distiller.student)#dq_16.student)\n",
    "dq_8_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "dq_8_tflite_model = dq_8_converter.convert()\n",
    "\n",
    "dq_16_converter = tf.lite.TFLiteConverter.from_keras_model(distiller.student)#dq_16.student)\n",
    "dq_16_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "dq_16_converter.target_spec.supported_types = [tf.float16]\n",
    "dq_16_tflite_model = dq_16_converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb7a5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure sizes of models.\n",
    "_, model_file = tempfile.mkstemp('.tflite')\n",
    "_, quant_file = tempfile.mkstemp('.tflite')\n",
    "_, q16_file = tempfile.mkstemp('.tflite')\n",
    "_, q8_file = tempfile.mkstemp('.tflite')\n",
    "_, distiller_file = tempfile.mkstemp('.tflite')\n",
    "_, qd_file = tempfile.mkstemp('.tflite')\n",
    "_, dq_file = tempfile.mkstemp('.tflite')\n",
    "_, dq_8_file = tempfile.mkstemp('.tflite')\n",
    "_, dq_16_file = tempfile.mkstemp('.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0b28ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(quant_file, 'wb') as f:\n",
    "  f.write(q_aware_tflite_model)\n",
    "\n",
    "with open(q8_file, 'wb') as f:\n",
    "  f.write(q8_tflite_model)\n",
    "\n",
    "with open(q16_file, 'wb') as f:\n",
    "  f.write(q16_tflite_model)\n",
    "\n",
    "with open(model_file, 'wb') as f:\n",
    "  f.write(model_tflite_model)\n",
    "\n",
    "with open(distiller_file, 'wb') as f:\n",
    "  f.write(distiller_tflite_model)\n",
    "\n",
    "with open(qd_file, 'wb') as f:\n",
    "  f.write(qd_tflite_model)\n",
    "\n",
    "with open(dq_file, 'wb') as f:\n",
    "  f.write(dq_tflite_model)\n",
    "\n",
    "with open(dq_8_file, 'wb') as f:\n",
    "  f.write(dq_8_tflite_model)\n",
    "\n",
    "with open(dq_16_file, 'wb') as f:\n",
    "  f.write(dq_16_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8792917a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model in Mb: 5.218955993652344\n",
      "Q Aware model in Mb: 1.3317031860351562\n",
      "Quantized 8 model in Mb: 1.32635498046875\n",
      "Quantized 16 model in Mb: 2.613739013671875\n",
      "Distiller model in Mb: 1.3147850036621094\n",
      "Quant -> Distill model in Mb: 1.3147850036621094\n",
      "Distill -> Quant model in Mb: 0.34481048583984375\n",
      "Distill -> Quant 8 model in Mb: 0.3414459228515625\n",
      "Distill -> Quant 16 model in Mb: 0.6615447998046875\n"
     ]
    }
   ],
   "source": [
    "print(\"Original model in Mb:\", os.path.getsize(model_file) / float(2**20))\n",
    "print(\"Q Aware model in Mb:\", os.path.getsize(quant_file) / float(2**20))\n",
    "print(\"Quantized 8 model in Mb:\", os.path.getsize(q8_file) / float(2**20))\n",
    "print(\"Quantized 16 model in Mb:\", os.path.getsize(q16_file) / float(2**20))\n",
    "print(\"Distiller model in Mb:\", os.path.getsize(distiller_file) / float(2**20))\n",
    "print(\"Quant -> Distill model in Mb:\", os.path.getsize(qd_file) / float(2**20))\n",
    "print(\"Distill -> Quant model in Mb:\", os.path.getsize(dq_file) / float(2**20))\n",
    "print(\"Distill -> Quant 8 model in Mb:\", os.path.getsize(dq_8_file) / float(2**20))\n",
    "print(\"Distill -> Quant 16 model in Mb:\", os.path.getsize(dq_16_file) / float(2**20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b6c45eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original accuracy: 0.704200029373169\n",
      "q aware accuracy: 0.6945000290870667\n",
      "distiller accuracy: 0.7062000036239624\n",
      "qd accuracy: 0.7062000036239624\n",
      "dq accuracy: 0.6780999898910522\n"
     ]
    }
   ],
   "source": [
    "print('original accuracy: ' + str(baseline_model_accuracy))\n",
    "print('q aware accuracy: ' + str(q_aware_model_accuracy))\n",
    "print('distiller accuracy: ' + str(distiller_accuracy))\n",
    "print('qd accuracy: ' + str(qd_accuracy))\n",
    "print('dq accuracy: ' + str(dq_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45f3a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        if i%100 == 0:\n",
    "            print('got to ' + str(i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "        \n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_digits)):\n",
    "        if prediction_digits[index] == test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cb84db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_interpreter = tf.lite.Interpreter(model_content=model_tflite_model)\n",
    "original_interpreter.allocate_tensors()\n",
    "\n",
    "q_aware_interpreter = tf.lite.Interpreter(model_content=q_aware_tflite_model)\n",
    "q_aware_interpreter.allocate_tensors()\n",
    "\n",
    "q8_interpreter = tf.lite.Interpreter(model_content=q8_tflite_model)\n",
    "q8_interpreter.allocate_tensors()\n",
    "\n",
    "q16_interpreter = tf.lite.Interpreter(model_content=q16_tflite_model)\n",
    "q16_interpreter.allocate_tensors()\n",
    "\n",
    "distiller_interpreter = tf.lite.Interpreter(model_content=distiller_tflite_model)\n",
    "distiller_interpreter.allocate_tensors()\n",
    "\n",
    "qd_interpreter = tf.lite.Interpreter(model_content=qd_tflite_model)\n",
    "qd_interpreter.allocate_tensors()\n",
    "\n",
    "dq_interpreter = tf.lite.Interpreter(model_content=dq_tflite_model)\n",
    "dq_interpreter.allocate_tensors()\n",
    "\n",
    "dq_8_interpreter = tf.lite.Interpreter(model_content=dq_8_tflite_model)\n",
    "dq_8_interpreter.allocate_tensors()\n",
    "\n",
    "dq_16_interpreter = tf.lite.Interpreter(model_content=dq_16_tflite_model)\n",
    "dq_16_interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d577001d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n"
     ]
    }
   ],
   "source": [
    "q_aware_accuracy = evaluate_model(q_aware_interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efeb8e43",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating q8...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n"
     ]
    }
   ],
   "source": [
    "print('evaluating q8...')\n",
    "q8_accuracy = evaluate_model(q8_interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d442dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating original...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating q16...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating distilled...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating qd...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating dq...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating dq 8...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n",
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n",
      "evaluating dq 16...\n",
      "got to 0\n",
      "got to 100\n",
      "got to 200\n",
      "got to 300\n",
      "got to 400\n",
      "got to 500\n",
      "got to 600\n",
      "got to 700\n",
      "got to 800\n",
      "got to 900\n",
      "got to 1000\n",
      "got to 1100\n",
      "got to 1200\n",
      "got to 1300\n",
      "got to 1400\n",
      "got to 1500\n",
      "got to 1600\n",
      "got to 1700\n",
      "got to 1800\n",
      "got to 1900\n",
      "got to 2000\n",
      "got to 2100\n",
      "got to 2200\n",
      "got to 2300\n",
      "got to 2400\n",
      "got to 2500\n",
      "got to 2600\n",
      "got to 2700\n",
      "got to 2800\n",
      "got to 2900\n",
      "got to 3000\n",
      "got to 3100\n",
      "got to 3200\n",
      "got to 3300\n",
      "got to 3400\n",
      "got to 3500\n",
      "got to 3600\n",
      "got to 3700\n",
      "got to 3800\n",
      "got to 3900\n",
      "got to 4000\n",
      "got to 4100\n",
      "got to 4200\n",
      "got to 4300\n",
      "got to 4400\n",
      "got to 4500\n",
      "got to 4600\n",
      "got to 4700\n",
      "got to 4800\n",
      "got to 4900\n",
      "got to 5000\n",
      "got to 5100\n",
      "got to 5200\n",
      "got to 5300\n",
      "got to 5400\n",
      "got to 5500\n",
      "got to 5600\n",
      "got to 5700\n",
      "got to 5800\n",
      "got to 5900\n",
      "got to 6000\n",
      "got to 6100\n",
      "got to 6200\n",
      "got to 6300\n",
      "got to 6400\n",
      "got to 6500\n",
      "got to 6600\n",
      "got to 6700\n",
      "got to 6800\n",
      "got to 6900\n",
      "got to 7000\n",
      "got to 7100\n",
      "got to 7200\n",
      "got to 7300\n",
      "got to 7400\n",
      "got to 7500\n",
      "got to 7600\n",
      "got to 7700\n",
      "got to 7800\n",
      "got to 7900\n",
      "got to 8000\n",
      "got to 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got to 8200\n",
      "got to 8300\n",
      "got to 8400\n",
      "got to 8500\n",
      "got to 8600\n",
      "got to 8700\n",
      "got to 8800\n",
      "got to 8900\n",
      "got to 9000\n",
      "got to 9100\n",
      "got to 9200\n",
      "got to 9300\n",
      "got to 9400\n",
      "got to 9500\n",
      "got to 9600\n",
      "got to 9700\n",
      "got to 9800\n",
      "got to 9900\n"
     ]
    }
   ],
   "source": [
    "print('evaluating original...')\n",
    "original_accuracy = evaluate_model(original_interpreter)\n",
    "#print('evaluating q aware...')\n",
    "#q_aware_accuracy = evaluate_model(q_aware_interpreter)\n",
    "#print('evaluating q8...')\n",
    "#q8_accuracy = evaluate_model(q8_interpreter)\n",
    "print('evaluating q16...')\n",
    "q16_accuracy = evaluate_model(q16_interpreter)\n",
    "print('evaluating distilled...')\n",
    "distiller_accuracy = evaluate_model(distiller_interpreter)\n",
    "print('evaluating qd...')\n",
    "qd_accuracy = evaluate_model(qd_interpreter)\n",
    "print('evaluating dq...')\n",
    "dq_accuracy = evaluate_model(dq_interpreter)\n",
    "print('evaluating dq 8...')\n",
    "dq_8_accuracy = evaluate_model(dq_8_interpreter)\n",
    "print('evaluating dq 16...')\n",
    "dq_16_accuracy = evaluate_model(dq_16_interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d25d1431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original accuracy  0.7042\n",
      "q aware accuracy  0.6955\n",
      "q8 accuracy  0.7036\n",
      "q16 accuracy  0.7042\n",
      "distiller accuracy  0.7062\n",
      "qd accuracy  0.7062\n",
      "dq accuracy  0.6793\n",
      "dq 8 accuracy  0.7059\n",
      "dq 16 accuracy  0.7062\n"
     ]
    }
   ],
   "source": [
    "print('original accuracy ', original_accuracy)\n",
    "print('q aware accuracy ', q_aware_accuracy)\n",
    "print('q8 accuracy ', q8_accuracy)\n",
    "print('q16 accuracy ', q16_accuracy)\n",
    "print('distiller accuracy ', distiller_accuracy)\n",
    "print('qd accuracy ', qd_accuracy)\n",
    "print('dq accuracy ', dq_accuracy)\n",
    "print('dq 8 accuracy ', dq_8_accuracy)\n",
    "print('dq 16 accuracy ', dq_16_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c6e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d7bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
